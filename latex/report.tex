\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{report}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    Esse relatório tem por objetivo expor o estudo feito por mim a partir
dos dados de dor crônica, e por consequência não possui o código
necessário para a reprodução do mesmo. O repositório com o código
completo se encontra em
(https://github.com/VictorHenrique317/ml-projeto-final)

    Os diferentes conjuntos de recursos são definidos da seguinte forma:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ``X\_questions'' são as perguntas feitas ao paciente durante a
  consulta, contendo informações relevantes para a análise.
\item
  ``X\_drugs'' consiste nos medicamentos que o paciente está tomando.
\item
  ``X'' representa a combinação dos conjuntos de recursos
  ``X\_questions'' e ``X\_drugs'', criando um conjunto mais abrangente.
\item
  ``X\_random'' é um conjunto de recursos aleatórios, que contêm
  variáveis sem uma relação direta com as perguntas ou medicamentos.
\end{enumerate}

Para melhorar a eficiência do modelo, algumas colunas não relevantes,
como a data de nascimento, foram removidas, bem como as colunas que
possuem um valor constante em todos os exemplos, já que essas não
fornecem informações úteis para a análise. Essa seleção cuidadosa de
recursos relevantes ajudará a concentrar a atenção do modelo nas
informações mais significativas.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{532}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:}\PY{l+m+mi}{182}\PY{p}{]} \PY{c+c1}{\PYZsh{} Id e data de nascimento são irrelevantes}
\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date\PYZus{}visit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} Data de visita não é relevante}
\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{46}\PY{p}{,} \PY{l+m+mi}{133}\PY{p}{,} \PY{l+m+mi}{158}\PY{p}{,} \PY{l+m+mi}{161}\PY{p}{]}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} Essas colunas são constantes}

\PY{n}{X\PYZus{}drugs} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{185}\PY{p}{:}\PY{p}{]}
\PY{n}{X\PYZus{}drugs} \PY{o}{=} \PY{n}{X\PYZus{}drugs}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{50}\PY{p}{,}\PY{l+m+mi}{51}\PY{p}{,}\PY{l+m+mi}{61}\PY{p}{,}\PY{l+m+mi}{92}\PY{p}{,}\PY{l+m+mi}{101}\PY{p}{,}\PY{l+m+mi}{111}\PY{p}{,}\PY{l+m+mi}{114}\PY{p}{,}\PY{l+m+mi}{121}\PY{p}{,}\PY{l+m+mi}{137}\PY{p}{,}\PY{l+m+mi}{140}\PY{p}{,}\PY{l+m+mi}{141}\PY{p}{,}
                                        \PY{l+m+mi}{142}\PY{p}{,}\PY{l+m+mi}{143}\PY{p}{,}\PY{l+m+mi}{148}\PY{p}{,}\PY{l+m+mi}{151}\PY{p}{,}\PY{l+m+mi}{152}\PY{p}{]}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} Essas colunas são constantes}

\PY{n}{X\PYZus{}random} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{rand}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} Para comparar a perfomance do modelo}
\PY{n}{X\PYZus{}random} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X\PYZus{}random}\PY{p}{)}
\PY{n}{X} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{p}{,} \PY{n}{X\PYZus{}drugs}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} A junção das duas tabelas}
\PY{n}{X} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Com base nos dados fornecidos, podemos extrair três diferentes variáveis
que indicam se o paciente teve melhora ou não. Essas variáveis são:
``y\_vas30'', ``y\_vas50'' e ``y\_gic''.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  ``y\_vas30'': Essa variável indica se o paciente apresentou uma
  melhora de pelo menos 30\% na escala de dor VAS (Visual Analog Scale -
  Escala Analógica Visual). Se o paciente teve uma redução de pelo menos
  30\% na intensidade da dor, a variável ``y\_vas30'' é marcada como
  positiva, indicando melhora. Caso contrário, é marcada como negativa.
\item
  ``y\_vas50'': Essa variável indica se o paciente teve uma melhora de
  pelo menos 50\% na escala VAS. Se o paciente teve uma redução de pelo
  menos 50\% na intensidade da dor, a variável ``y\_vas50'' é marcada
  como positiva, indicando melhora. Caso contrário, é marcada como
  negativa.
\item
  ``y\_gic'': Essa variável representa a avaliação de melhora feita pelo
  médico utilizando o Global Impression of Change (GIC). O médico avalia
  se houve uma melhora geral no estado de saúde do paciente. Se o médico
  considerar que houve melhora, a variável ``y\_gic'' é marcada como
  positiva. Caso contrário, é marcada como negativa.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{533}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Y} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{182}\PY{p}{:}\PY{l+m+mi}{185}\PY{p}{]}

\PY{n}{y\PYZus{}vas30} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{Y}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{y\PYZus{}vas50} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{Y}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{y\PYZus{}gic} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{Y}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Neste ponto, nos deparamos com três alvos diferentes e precisamos
decidir qual deles faz mais sentido utilizar. Considerei que não seria
adequado escolher apenas um deles e ignorar os demais. Portanto, decidi
criar uma nova variável que leve em consideração as três diferentes
avaliações de melhora, duas feitas pelo paciente e uma feita pelo
médico.

Primeiramente, criei a variável ``y\_perceived'', que representa a
melhora percebida pelo paciente. Essa variável é definida como a união
das variáveis ``y\_vas30'' e ``y\_vas50'', pois desejo capturar qualquer
tipo de melhora percebida pelo paciente, seja ela pequena (30\%) ou
significativa (50\%).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{534}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y\PYZus{}perceived} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{logical\PYZus{}or}\PY{p}{(}\PY{n}{y\PYZus{}vas30}\PY{p}{,} \PY{n}{y\PYZus{}vas50}\PY{p}{)}
\PY{n}{y\PYZus{}perceived} \PY{o}{=} \PY{n}{y\PYZus{}perceived}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
\PY{n}{y\PYZus{}perceived} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y\PYZus{}perceived}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    O alvo ``y'' é definido como a interseção entre a melhora percebida e o
GIC (Global Impression of Change - Impressão Global de Mudança). Essa
definição é baseada na necessidade de o paciente perceber alguma melhora
(indicado por ``y\_perceived'') e o médico concordar com essa percepção
(indicado por ``y\_gic''). Após uma análise experimental, verifiquei que
essa é a definição de alvo que melhor se ajusta aos dados, em comparação
com as outras cinco definições mencionadas anteriormente.

Dessa forma, além de fazer sentido intuitivamente, a expressividade
dessa definição também foi verificada experimentalmente, demonstrando
sua adequação para o propósito do estudo.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{logical\PYZus{}and}\PY{p}{(}\PY{n}{y\PYZus{}perceived}\PY{p}{,} \PY{n}{y\PYZus{}gic}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{y}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Ao adotar a definição de alvo ``y'' como a interseção entre a melhora
percebida e o GIC, a distribuição dos dados resultantes fica
desbalanceada. Apenas 15\% dos exemplos são classificados como pacientes
que apresentaram melhora, de acordo com o nosso alvo ``y''.

Essa baixa porcentagem de casos positivos em ``y'' faz sentido, levando
em consideração a reunião em que foi discutido que a maioria dos
pacientes que sofrem de dor crônica não apresentam melhora
significativa. Portanto, a distribuição desigual é uma representação
adequada da realidade clínica em relação à melhora dos pacientes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{535}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}gic é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}gic}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}gic}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}vas30 é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}vas30}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}vas30}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}vas50 é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}vas50}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}vas50}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}perceived é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}perceived}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}perceived}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
A porcentagem de casos positivos em y\_gic é 28.96\%
A porcentagem de casos positivos em y\_vas30 é 43.84\%
A porcentagem de casos positivos em y\_vas50 é 35.84\%
A porcentagem de casos positivos em y\_perceived é 43.84\%
A porcentagem de casos positivos em y é 15.04\%
    \end{Verbatim}

    O objetivo aqui é alcançar uma distribuição equilibrada entre os
exemplos positivos e negativos. Isso garantirá que o modelo tenha a
mesma capacidade de classificar ambos os casos, sem favorecer uma
categoria em relação à outra. No entanto, a única maneira que tenho
disponível para alcançar esse equilíbrio é remover os casos negativos em
excesso presentes nos dados originais.

Essa situação apresenta um desafio para o modelo, uma vez que é
necessário reduzir o tamanho do conjunto de treinamento, que já é
limitado, contendo apenas 625 exemplos, para 201 exemplos. Sendo assim,
tornar o modelo igualmente capaz de classificar ambas as categorias tem
uma consequência negativa evidente: uma redução na qualidade devido à
quantidade de dados reduzida. Mais adiante, mostrarei como diferentes
distribuições de exemplos positivos (pacientes que apresentaram melhora)
e negativos (pacientes que não apresentaram melhora) afetam o
classificador.

Apesar de todos os fatos mencionados, acredito que, por se tratar de um
modelo com grande responsabilidade na área da saúde, é essencial que ele
seja justo e equilibrado na classificação dos casos, minimizando assim
os falsos negativos e falsos positivos que, nesse contexto, representam
cenários prejudiciais para as pessoas. Além disso, levar em consideração
todos os 625 dados originais torna o modelo ineficaz, como demonstrarei
mais adiante.

A distribuição equilibrada dos targets também ajuda a evitar problemas
como o viés do modelo em direção à categoria majoritária, que pode
ocorrer quando há um desequilíbrio significativo na distribuição dos
dados. É importante ressaltar que a obtenção de uma distribuição
equilibrada não apenas melhora a qualidade do modelo, mas também aumenta
sua confiabilidade e aplicabilidade em diferentes cenários e contextos.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{536}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n}{zero\PYZus{}rows} \PY{o}{=} \PY{n}{y}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{p}{(}\PY{n}{y} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{)}\PY{o}{.}\PY{n}{all}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}
\PY{n}{delete\PYZus{}rows} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{zero\PYZus{}rows}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{zero\PYZus{}rows}\PY{p}{)}\PY{o}{/}\PY{l+m+mf}{1.25}\PY{p}{)}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{n}{X} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{X\PYZus{}drugs} \PY{o}{=} \PY{n}{X\PYZus{}drugs}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{X\PYZus{}random} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{delete}\PY{p}{(}\PY{n}{X\PYZus{}random}\PY{p}{,} \PY{n}{delete\PYZus{}rows}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{n}{y\PYZus{}gic} \PY{o}{=} \PY{n}{y\PYZus{}gic}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{y\PYZus{}vas30} \PY{o}{=} \PY{n}{y\PYZus{}vas30}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{y\PYZus{}vas50} \PY{o}{=} \PY{n}{y\PYZus{}vas50}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{y\PYZus{}perceived} \PY{o}{=} \PY{n}{y\PYZus{}perceived}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{y}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{delete\PYZus{}rows}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
(625, 1)
(201, 312)
(201, 175)
(201, 137)
(201, 1)
    \end{Verbatim}

    É possível observar que, com a extração do excesso de casos negativos, a
distribuição dos targets, incluindo ``y'' e os outros targets
alternativos, tornou-se equilibrada.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{537}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}gic é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}gic}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}gic}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}vas30 é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}vas30}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}vas30}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}vas50 é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}vas50}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}vas50}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y\PYZus{}perceived é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y\PYZus{}perceived}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y\PYZus{}perceived}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A porcentagem de casos positivos em y é }\PY{l+s+si}{\PYZob{}}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{o}{/}\PY{n}{y}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
A porcentagem de casos positivos em y\_gic é 54.73\%
A porcentagem de casos positivos em y\_vas30 é 60.70\%
A porcentagem de casos positivos em y\_vas50 é 51.24\%
A porcentagem de casos positivos em y\_perceived é 60.70\%
A porcentagem de casos positivos em y é 46.77\%
    \end{Verbatim}

    Pré-processamento dos dados.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{538}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Codificando as variáveis categóricas}
\PY{n}{le} \PY{o}{=} \PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}
\PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{X\PYZus{}questions}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{k}{if} \PY{n}{X\PYZus{}questions}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bool}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        \PY{n}{X\PYZus{}questions}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}

\PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{X\PYZus{}drugs}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{k}{if} \PY{n}{X\PYZus{}drugs}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bool}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        \PY{n}{X\PYZus{}drugs}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}

\PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{X}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{k}{if} \PY{n}{X}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bool}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        \PY{n}{X}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imputando os valores que faltam}
\PY{n}{imp} \PY{o}{=} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{imp}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{p}{)}
\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{imp}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{p}{)}

\PY{n}{imp} \PY{o}{=} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{imp}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{p}{)}
\PY{n}{X\PYZus{}drugs} \PY{o}{=} \PY{n}{imp}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{p}{)}

\PY{n}{imp} \PY{o}{=} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{imp}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{)}
\PY{n}{X} \PY{o}{=} \PY{n}{imp}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Normalizando os dados}
\PY{n}{scaler} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
\PY{n}{X} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X}\PY{p}{)}
\PY{n}{X\PYZus{}drugs} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{p}{)}
\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{p}{)}
\PY{n}{X\PYZus{}random} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}random}\PY{p}{)}

\PY{n}{X} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X}\PY{p}{)}
\PY{n}{X\PYZus{}drugs} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X\PYZus{}drugs}\PY{p}{)}
\PY{n}{X\PYZus{}questions} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X\PYZus{}questions}\PY{p}{)}
\PY{n}{X\PYZus{}random} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X\PYZus{}random}\PY{p}{)}

\PY{n}{y\PYZus{}gic} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y\PYZus{}gic}\PY{p}{)}
\PY{n}{y\PYZus{}vas30} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y\PYZus{}vas30}\PY{p}{)}
\PY{n}{y\PYZus{}vas50} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y\PYZus{}vas50}\PY{p}{)}
\PY{n}{y\PYZus{}perceived} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y\PYZus{}perceived}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{y}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Para treinar os diferentes algoritmos selecionados, defini funções
específicas. A fim de obter uma melhor estimativa do erro esperado, os
erros de teste são calculados usando a técnica de validação cruzada com
5 `folds'. Durante esse processo, as acurácias dos modelos também são
registradas para cada iteração da validação cruzada.

Realizei uma tentativa de aplicar o aprendizado semi-supervisionado,
utilizando os dados deletados como exemplos não rotulados. No entanto,
os resultados obtidos não apresentaram melhoras significativas. Por
questões de espaço, não será possível incluir o código desenvolvido
neste documento, mas ele está disponível no repositório mencionado no
início do relatório.

Na seleção dos algoritmos, optei por dois que demonstraram boa
eficiência mesmo com conjuntos de dados menores: XGBoosting e
RandomForest. Além disso, por curiosidade e para fins comparativos,
também treinei MLPs, que naturalmente requerem uma quantidade maior de
dados.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{539}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{trainClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{clf}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{n}{kf} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
    \PY{n}{empirical\PYZus{}losses} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{n}{test\PYZus{}losses} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{n}{empirical\PYZus{}accuracies} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{n}{test\PYZus{}accuracies} \PY{o}{=} \PY{p}{[}\PY{p}{]}

    \PY{k}{for} \PY{n}{train\PYZus{}indices}\PY{p}{,} \PY{n}{test\PYZus{}indices} \PY{o+ow}{in} \PY{n}{kf}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X}\PY{p}{)}\PY{p}{:}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{train\PYZus{}indices}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{test\PYZus{}indices}\PY{p}{]}
        \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{y}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{train\PYZus{}indices}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{test\PYZus{}indices}\PY{p}{]}

        \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)} \PY{c+c1}{\PYZsh{} classificador generico}

        \PY{n}{empirical\PYZus{}loss} \PY{o}{=} \PY{n}{log\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{)}
        \PY{n}{test\PYZus{}loss} \PY{o}{=} \PY{n}{log\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}\PY{p}{)}

        \PY{n}{empirical\PYZus{}accuracy} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
        \PY{n}{test\PYZus{}accuracy} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}

        \PY{n}{empirical\PYZus{}losses}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{empirical\PYZus{}loss}\PY{p}{)}
        \PY{n}{test\PYZus{}losses}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{test\PYZus{}loss}\PY{p}{)}

        \PY{n}{empirical\PYZus{}accuracies}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{empirical\PYZus{}accuracy}\PY{p}{)}
        \PY{n}{test\PYZus{}accuracies}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{test\PYZus{}accuracy}\PY{p}{)}

    \PY{n}{empirical\PYZus{}loss} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{empirical\PYZus{}losses}\PY{p}{)}
    \PY{n}{test\PYZus{}loss} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{test\PYZus{}losses}\PY{p}{)}

    \PY{n}{empirical\PYZus{}accuracy} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{empirical\PYZus{}accuracies}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}
    \PY{n}{test\PYZus{}accuracy} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{test\PYZus{}accuracies}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}

    \PY{k}{if} \PY{n}{print\PYZus{}accuracy}\PY{p}{:}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{empirical\PYZus{}accuracy: }\PY{l+s+si}{\PYZob{}}\PY{n}{empirical\PYZus{}accuracy}\PY{l+s+si}{:}\PY{l+s+s2}{ .2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{} | test\PYZus{}accuracy: }\PY{l+s+si}{\PYZob{}}\PY{n}{test\PYZus{}accuracy}\PY{l+s+si}{:}\PY{l+s+s2}{ .2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZpc{} }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

    \PY{k}{return} \PY{p}{(}\PY{n}{empirical\PYZus{}loss}\PY{p}{,} \PY{n}{test\PYZus{}loss}\PY{p}{,} \PY{n}{test\PYZus{}accuracy}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{trainXGBBoostingClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{n}{clf} \PY{o}{=} \PY{n}{xgb}\PY{o}{.}\PY{n}{XGBClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{max\PYZus{}depth}\PY{p}{,}  \PY{n}{gamma}\PY{o}{=}\PY{n}{gamma}\PY{p}{,} \PY{n}{eta}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{min\PYZus{}child\PYZus{}weight}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{subsample}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} 
                            \PY{n}{colsample\PYZus{}bytree}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{scale\PYZus{}pos\PYZus{}weight}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{k}{return} \PY{n}{trainClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{clf}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{trainMLPClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{hidden\PYZus{}layer\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{n}{clf} \PY{o}{=} \PY{n}{MLPClassifier}\PY{p}{(}\PY{n}{hidden\PYZus{}layer\PYZus{}sizes}\PY{o}{=}\PY{p}{(}\PY{n}{hidden\PYZus{}layer\PYZus{}size}\PY{p}{,}\PY{p}{)}\PY{p}{,} \PY{n}{solver}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sgd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{learning\PYZus{}rate\PYZus{}init}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,}
                        \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{2000}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{k}{return} \PY{n}{trainClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{clf}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{trainRandomForestClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{n}{clf} \PY{o}{=}\PY{n}{clf} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{max\PYZus{}depth}\PY{p}{)}
    \PY{k}{return} \PY{n}{trainClassifier}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{clf}\PY{p}{,} \PY{n}{print\PYZus{}accuracy}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Agora estamos na fase de seleção de modelos. Para cada combinação de
algoritmo e conjunto de características, plotei o gráfico de erro em
relação à capacidade, a fim de determinar o nível ideal de complexidade
e o conjunto de características mais adequado para a classificação.

\begin{itemize}
\item
  No caso das MLP's de 3 camadas, a medida de complexidade é determinada
  pelo número de neurônios na camada oculta.
\item
  Para as Random Forests, a medida de complexidade é definida pela
  profundidade máxima das árvores, que são os classificadores
  individuais.
\item
  No XGBoost, a medida de complexidade também é determinada pela
  profundidade máxima das árvores, que são os classificadores
  individuais.
\end{itemize}

Realizei a comparação dos diferentes modelos inicialmente considerando
apenas o conjunto de características X. Após a seleção do modelo, é
possível analisar como os diferentes conjuntos de características afetam
a capacidade preditiva.

    Selecionei o XGBoost como modelo preferencial devido aos resultados
ligeiramente melhores em termos de menor erro de teste e maior acurácia,
em comparação com a Random Forest. Além disso, o XGBoost oferece mais
hiperparâmetros para ajustar a qualidade do modelo.

Como esperado, o desempenho da MLP é baixo e inconsistente ao longo dos
diferentes níveis de complexidade.

No contexto atual, o ajuste de hiperparâmetros não é tão relevante, pois
a qualidade geral dos modelos é baixa devido ao pequeno número de dados
disponíveis.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{544}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plots/manual/models\PYZus{}capacity\PYZus{}x.jpg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{544}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{report_files/report_21_0.jpg}
    \end{center}
    { \hspace*{\fill} \\}
    

    Agora que selecionamos o melhor modelo podemos analisar como os
diferentes conjuntos de features afetam a capacidade preditiva. Para
fins comparação gerei X\_random, um conjunto de features aleatórias que
nos permite ver o quão menor o erro de teste de cada conjunto está em
relação ao erro de teste gerado a partir de valores aleatórios.

X\_questions e X\_drugs geram um desempenho semelhante, porém
x\_questions gera resultados levemente melhores. Quando usamos todas a
as features disponíveis (X) temos o melhor modelo por uma faixa bem
pequena.

Com esses resultados não conseguimos afirmar com certeza se os remédios
que o paciente toma podem ser usados para predizer se ele vai ter uma
melhora em sua dor crônica ou não. Isso porque o melhor desempenho do
modelo que usa o conjunto X pode ser explicado tanto pelo presença das
features de remédios quanto pelo aumento da dimensionalidade dos dados.
Lembrando que quanto maior a dimensionalidade dos dados maior a chance
do modelo ser linearmente separável, e por consequência ter um melhor
desempenho.

Porém, não podemos esquecer do fato que o modelo que usa X\_drugs é tão
bom quanto o que usa X\_questions. Isso pode ser um indício que os
remédios tem sim alguma capacidade preditiva, já que já foi comprovado
que X\_questions pode ser usado para fazer essa predição (como discutido
em nossa reunião).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{545}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plots/manual/xgboost\PYZus{}features.jpg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{545}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{report_files/report_23_0.jpg}
    \end{center}
    { \hspace*{\fill} \\}
    

    Para fazer uma última análise do modelo obtido usaremos o princípio da
navalha de Ockham para escolher o conjunto de features X\_questions, já
que ele é menos complexo que X e gera um modelo com aproximadamente a
mesma qualidade.

Podemos observar que pela confusion matrix dos dados originais, com uma
distribuição assimétrica para o lado dos dados negativos, que o modelo é
completamente desbalanceado, só sabendo identificar verdadeiros
negativos. E se observamos bem a confusion matrix desse classificador,
podemos ver que ele só prediz 0, qualquer que seja a entrada. A acurácia
elevada desse modelo é explicada pela própria distribuição dos dados,
como 85\% dos exemplos são de casos negativos se o modelo predizer 0
para todos as entradas ele em média vai acertar 85\% das vezes. Ao usar
uma distribuição balanceada para avaliar esse classificador a acurácia é
pior que adivinhar aleatoriamente.

O modelo que usa a distribuição equilibrada, apesar de ter pior
acurácia, é mais balanceado em suas classificações. Tendo uma taxa de
acerto de 63\% ele é ligeiramente melhor que adivinhar aleatoriamente.

Por fim, o modelo com uma distribuição maior de casos positivos é
semelhante ao primeiro avaliado, mas apresenta um desequilíbrio para o
lado direito da matriz de confusão, com mais previsões positivas e
falsos positivos. A alta acurácia desse modelo não é confiável, pois ele
utiliza o menor conjunto de dados, sendo necessário remover mais
exemplos para obter uma distribuição com mais casos positivos. Esse
valor elevado de acurácia é uma anomalia de variância, pois o conjunto
pequeno de dados de treinamento favorece o treinamento de um modelo
``overfitado'' que não é generalizável quando adicionamos mais dados.

Portanto, é importante ter cuidado ao interpretar a acurácia do modelo
que apresenta um desequilíbrio significativo na matriz de confusão. É
preferível escolher um modelo que mantenha um equilíbrio adequado entre
as previsões positivas e negativas.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plots/manual/confusion\PYZus{}matrices.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{5}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{report_files/report_25_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    Vejamos quais são as features mais importantes para o classificador
XGBoost.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plots/manual/xgboost\PYZus{}feat\PYZus{}imp.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{7}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{report_files/report_27_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    Concluindo, é necessário ter mais exemplos de casos positivos para
afirmar com responsabilidade se a adição dos dados de remédios cria
modelos melhores em comparação com apenas os dados das perguntas. Com
base nos resultados e no meu conhecimento do conjunto de dados
disponível, não é possível afirmar estatisticamente se o conjunto de
features ``X'' é melhor do que ``X\_questions''. No entanto, é visível
que o conjunto de features ``X\_drugs'' possui um poder preditivo
semelhante ao de ``X\_questions''.

Acredito firmemente que meu estudo tem a capacidade de responder a essa
pergunta, desde que sejam fornecidos mais exemplos de casos. Se eu
tivesse a oportunidade de continuar desenvolvendo esse trabalho, focaria
nessa questão e no entendimento das features por meio de diálogos com
médicos especialistas. Isso porque remover features que não são
relevantes para o problema reduziria a dimensionalidade dos dados,
resultando em modelos melhores para a mesma quantidade de exemplos.

Abaixo, mostro um gráfico que justifica minha crença no potencial do meu
estudo. Nele, é possível observar como a acurácia do modelo evolui à
medida que o tamanho do conjunto de dados aumenta (distribuído de forma
equilibrada, como discutido anteriormente). Podemos ver que a acurácia
não converge para o valor máximo, o que indica que ainda há espaço para
melhorar a qualidade do modelo ao aumentar a quantidade de dados
disponíveis.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plots/manual/accuracy\PYZus{}conv\PYZus{}data.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{9}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{report_files/report_29_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
