{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repositório com o código desenvolvido para realizar o trabalho (https://github.com/VictorHenrique317/ml-projeto-final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost\n",
    "# %pip install seaborn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from IPython.core.display import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo os diferentes conjuntos de features.\n",
    "- X_questions são as perguntas feitas para o paciente durante a consulta.\n",
    "- X_drugs são os remédios que o paciente toma.\n",
    "- X é a junção de X_Questions e X_drugs.\n",
    "- X_random é um conjunto de features aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold: 0\n",
      "     0.00%... | Accuracy on batch 1:  50.00%\n",
      "     8.33%... | Accuracy on batch 2:  43.75%\n",
      "     16.67%... | Accuracy on batch 3:  43.75%\n",
      "     25.00%... | Accuracy on batch 4:  43.75%\n",
      "     33.33%... | Accuracy on batch 5:  46.88%\n",
      "     41.67%... | Accuracy on batch 6:  53.12%\n",
      "     50.00%... | Accuracy on batch 7:  46.88%\n",
      "     58.33%... | Accuracy on batch 8:  50.00%\n",
      "     66.67%... | Accuracy on batch 9:  50.00%\n",
      "     75.00%... | Accuracy on batch 10:  46.88%\n",
      "     83.33%... | Accuracy on batch 11:  50.00%\n",
      "     91.67%... | Accuracy on batch 12:  50.00%\n",
      "kfold: 1\n",
      "     0.00%... | Accuracy on batch 1:  61.29%\n",
      "     8.33%... | Accuracy on batch 2:  58.06%\n",
      "     16.67%... | Accuracy on batch 3:  58.06%\n",
      "     25.00%... | Accuracy on batch 4:  61.29%\n",
      "     33.33%... | Accuracy on batch 5:  64.52%\n",
      "     41.67%... | Accuracy on batch 6:  64.52%\n",
      "     50.00%... | Accuracy on batch 7:  67.74%\n",
      "     58.33%... | Accuracy on batch 8:  64.52%\n",
      "     66.67%... | Accuracy on batch 9:  58.06%\n",
      "     75.00%... | Accuracy on batch 10:  74.19%\n",
      "     83.33%... | Accuracy on batch 11:  58.06%\n",
      "     91.67%... | Accuracy on batch 12:  61.29%\n",
      "kfold: 2\n",
      "     0.00%... | Accuracy on batch 1:  64.52%\n",
      "     8.33%... | Accuracy on batch 2:  54.84%\n",
      "     16.67%... | Accuracy on batch 3:  51.61%\n",
      "     25.00%... | Accuracy on batch 4:  51.61%\n",
      "     33.33%... | Accuracy on batch 5:  54.84%\n",
      "     41.67%... | Accuracy on batch 6:  48.39%\n",
      "     50.00%... | Accuracy on batch 7:  51.61%\n",
      "     58.33%... | Accuracy on batch 8:  45.16%\n",
      "     66.67%... | Accuracy on batch 9:  45.16%\n",
      "     75.00%... | Accuracy on batch 10:  41.94%\n",
      "     83.33%... | Accuracy on batch 11:  45.16%\n",
      "     91.67%... | Accuracy on batch 12:  45.16%\n",
      "kfold: 3\n",
      "     0.00%... | Accuracy on batch 1:  54.84%\n",
      "     8.33%... | Accuracy on batch 2:  54.84%\n",
      "     16.67%... | Accuracy on batch 3:  54.84%\n",
      "     25.00%... | Accuracy on batch 4:  58.06%\n",
      "     33.33%... | Accuracy on batch 5:  51.61%\n",
      "     41.67%... | Accuracy on batch 6:  58.06%\n",
      "     50.00%... | Accuracy on batch 7:  51.61%\n",
      "     58.33%... | Accuracy on batch 8:  48.39%\n",
      "     66.67%... | Accuracy on batch 9:  48.39%\n",
      "     75.00%... | Accuracy on batch 10:  48.39%\n",
      "     83.33%... | Accuracy on batch 11:  51.61%\n",
      "     91.67%... | Accuracy on batch 12:  54.84%\n",
      "kfold: 4\n",
      "     0.00%... | Accuracy on batch 1:  61.29%\n",
      "     8.33%... | Accuracy on batch 2:  58.06%\n",
      "     16.67%... | Accuracy on batch 3:  54.84%\n",
      "     25.00%... | Accuracy on batch 4:  51.61%\n",
      "     33.33%... | Accuracy on batch 5:  58.06%\n",
      "     41.67%... | Accuracy on batch 6:  58.06%\n",
      "     50.00%... | Accuracy on batch 7:  61.29%\n",
      "     58.33%... | Accuracy on batch 8:  58.06%\n",
      "     66.67%... | Accuracy on batch 9:  54.84%\n",
      "     75.00%... | Accuracy on batch 10:  54.84%\n",
      "     83.33%... | Accuracy on batch 11:  54.84%\n",
      "     91.67%... | Accuracy on batch 12:  54.84%\n",
      "empirical_accuracy:  95.50% | test_accuracy:  53.23% \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def trainClassifier(X_labeled, y_labeled, clusters, clf, print_accuracy=False):\n",
    "    # cosine 52%\n",
    "    metric='l2'\n",
    "    y_labeled = y_labeled.reset_index(drop=True)\n",
    "    # Achando os negativos mais proximos\n",
    "    n_neighbors = len(clusters[0])\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric=metric)\n",
    "    nn.fit(clusters[0])\n",
    "\n",
    "    true_negatives_indices = y_labeled.index[(y_labeled == 0).all(axis=1)]\n",
    "    true_negatives = X_labeled.iloc[true_negatives_indices, :]\n",
    "    true_negatives = true_negatives.mean(axis=0).values.reshape(1, -1)\n",
    "\n",
    "    distances, indices = nn.kneighbors(true_negatives)\n",
    "    mask = distances < 15.0\n",
    "    indices = indices[mask]\n",
    "    nearest_negatives = clusters[0].iloc[indices.ravel(), :]\n",
    "    \n",
    "    # Achando os positivos mais proximos\n",
    "    n_neighbors = len(clusters[1])\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric=metric)\n",
    "    nn.fit(clusters[1])\n",
    "\n",
    "    true_positives_indices = y_labeled.index[(y_labeled == 1).all(axis=1)]\n",
    "    true_positives = X_labeled.iloc[true_positives_indices, :]\n",
    "    true_positives = true_positives.mean(axis=0).values.reshape(1, -1)\n",
    "\n",
    "    distances, indices = nn.kneighbors(true_positives)\n",
    "    mask = distances < 15.0\n",
    "    indices = indices[mask]\n",
    "    nearest_positives = clusters[1].iloc[indices.ravel(), :]\n",
    "\n",
    "    X_unlabeled = pd.DataFrame(nearest_negatives.iloc[0:1, :])\n",
    "    X_unlabeled = np.concatenate((X_unlabeled, nearest_positives.iloc[0:1, :]), axis=0)\n",
    "    min_length = min(len(nearest_negatives), len(nearest_positives))\n",
    "\n",
    "    for i in range(1, min_length):\n",
    "        X_unlabeled = np.concatenate((X_unlabeled, nearest_negatives.iloc[i: i+1, :]), axis=0)\n",
    "        X_unlabeled = np.concatenate((X_unlabeled, nearest_positives.iloc[i: i+1, :]), axis=0)\n",
    "\n",
    "    if len(nearest_negatives) > min_length:\n",
    "        X_unlabeled = np.concatenate((X_unlabeled, nearest_negatives.iloc[min_length:, :]), axis=0)\n",
    "    elif len(nearest_positives) > min_length:\n",
    "        X_unlabeled = np.concatenate((X_unlabeled, nearest_positives.iloc[min_length:, :]), axis=0)\n",
    "\n",
    "    batch_size = 20\n",
    "    repeats = X_unlabeled.shape[0] // batch_size\n",
    "    X_unlabeled = pd.DataFrame(X_unlabeled)\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    empirical_losses = []\n",
    "    test_losses = []\n",
    "    empirical_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for i, (train_indices, test_indicies) in enumerate(kf.split(X_labeled)):\n",
    "        print(f\"kfold: {i}\")\n",
    "        X_train, X_test = X_labeled.iloc[train_indices], X_labeled.iloc[test_indicies]\n",
    "        y_train, y_test = y_labeled.iloc[train_indices], y_labeled.iloc[test_indicies]\n",
    "        \n",
    "        for i in range(0, repeats):\n",
    "            clf.fit(X_train, y_train) # classificador generico\n",
    "            print(f\"    {i/repeats*100: .2f}%... | Accuracy on batch {i + 1}: {clf.score(X_test, y_test) * 100: .2f}%\")\n",
    "\n",
    "            delta_X_batch = pd.DataFrame(X_unlabeled.iloc[i*batch_size : batch_size*(i+1), :])\n",
    "            delta_y_batch = pd.DataFrame(clf.predict(delta_X_batch))\n",
    "\n",
    "            X_train = pd.concat([X_train, delta_X_batch], axis=0)\n",
    "            y_train = pd.concat([y_train, delta_y_batch], axis=0)\n",
    "\n",
    "        empirical_loss = log_loss(y_train, clf.predict(X_train))\n",
    "        test_loss = log_loss(y_test, clf.predict(X_test))\n",
    "\n",
    "        empirical_accuracy = clf.score(X_train, y_train)\n",
    "        test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "        empirical_losses.append(empirical_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        empirical_accuracies.append(empirical_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "    empirical_loss = np.mean(empirical_losses)\n",
    "    test_loss = np.mean(test_losses)\n",
    "\n",
    "    empirical_accuracy = np.mean(empirical_accuracies) * 100\n",
    "    test_accuracy = np.mean(test_accuracies) * 100\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2)\n",
    "    # for i in range(0, repeats):\n",
    "    #     clf.fit(X_train, y_train) # classificador generico\n",
    "    #     print(f\"{i/repeats*100: .2f}%... | Accuracy on batch {i + 1}: {clf.score(X_test, y_test) * 100: .2f}%\")\n",
    "\n",
    "    #     delta_X_batch = pd.DataFrame(X_unlabeled.iloc[i*batch_size : batch_size*(i+1), :])\n",
    "    #     delta_y_batch = pd.DataFrame(clf.predict(delta_X_batch))\n",
    "\n",
    "    #     X_train = pd.concat([X_train, delta_X_batch], axis=0)\n",
    "    #     y_train = pd.concat([y_train, delta_y_batch], axis=0)\n",
    "        \n",
    "    # empirical_loss = log_loss(y_train, clf.predict(X_train))\n",
    "    # test_loss = log_loss(y_test, clf.predict(X_test))\n",
    "\n",
    "    # empirical_accuracy = clf.score(X_train, y_train)\n",
    "    # test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    if print_accuracy:\n",
    "        print(f\"empirical_accuracy: {empirical_accuracy: .2f}% | test_accuracy: {test_accuracy: .2f}% \")\n",
    "\n",
    "    return (empirical_loss, test_loss)\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "X_questions = data.iloc[:, 2:182] # Id e data de nascimento são irrelevantes\n",
    "X_questions = X_questions.drop('date_visit', axis=1) # Data de visita não é relevante\n",
    "X_questions = X_questions.drop(X_questions.columns[[46, 133, 158, 161]], axis=1) # Essas colunas são constantes\n",
    "\n",
    "X_drugs = data.iloc[:, 185:]\n",
    "X_drugs = X_drugs.drop(X_drugs.columns[[50,51,61,92,101,111,114,121,137,140,141,\n",
    "                                        142,143,148,151,152]], axis=1) # Essas colunas são constantes\n",
    "\n",
    "X_random = np.random.rand(X_questions.shape[0], 1) # Para comparar a perfomance do modelo\n",
    "\n",
    "# Codificando as variáveis categóricas\n",
    "le = LabelEncoder()\n",
    "for col in X_questions.columns:\n",
    "    if X_questions[col].dtype == 'bool':\n",
    "        X_questions[col] = le.fit_transform(X_questions[col])\n",
    "\n",
    "for col in X_drugs.columns:\n",
    "    if X_drugs[col].dtype == 'bool':\n",
    "        X_drugs[col] = le.fit_transform(X_drugs[col])\n",
    "\n",
    "# Imputando os valores que faltam\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp.fit(X_questions)\n",
    "X_questions = imp.transform(X_questions)\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp.fit(X_drugs)\n",
    "X_drugs = imp.transform(X_drugs)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_drugs = scaler.fit_transform(X_drugs)\n",
    "X_questions = scaler.fit_transform(X_questions)\n",
    "X_random = scaler.fit_transform(X_random)\n",
    "\n",
    "X_questions = pd.DataFrame(X_questions)\n",
    "X_drugs = pd.DataFrame(X_drugs)\n",
    "X_random = pd.DataFrame(X_random)\n",
    "\n",
    "Y = data.iloc[:, 182:185]\n",
    "\n",
    "y_vas30 = Y.iloc[:, 0:1].values.ravel()\n",
    "y_vas50 = Y.iloc[:, 1:2].values.ravel()\n",
    "y_gic = Y.iloc[:, 2:3].values.ravel()\n",
    "\n",
    "y_perceived = np.logical_and(y_vas30, y_vas50)\n",
    "y_perceived = y_perceived.astype(int)\n",
    "\n",
    "y = np.logical_and(y_perceived, y_gic)\n",
    "y = y.astype(int)\n",
    "y = pd.DataFrame(y)\n",
    "    \n",
    "one_rows = pd.DataFrame(y.index[(y == 1).all(axis=1)]) # Achando os indices das linhas que tem y=1\n",
    "zero_rows = pd.DataFrame( y.index[(y == 0).all(axis=1)]) # Achando os indices das linhas que tem y=0\n",
    "zero_rows = zero_rows.sample(n=one_rows.shape[0], random_state=42)\n",
    "\n",
    "# LABELED DATA\n",
    "X_questions_labeled = X_questions.iloc[one_rows[0].tolist() + zero_rows[0].tolist(), :].astype(int)\n",
    "X_drugs_labeled = X_drugs.iloc[one_rows[0].tolist() + zero_rows[0].tolist(), :].astype(int)\n",
    "X_labeled = np.concatenate((X_questions_labeled, X_drugs_labeled), axis=1).astype(int) # A junção das duas tabelas\n",
    "\n",
    "X_questions_labeled = pd.DataFrame(X_questions_labeled)\n",
    "X_drugs_labeled = pd.DataFrame(X_drugs_labeled)\n",
    "X_labeled = pd.DataFrame(X_labeled)\n",
    "\n",
    "y_labeled = y.iloc[one_rows[0].tolist() + zero_rows[0].tolist(), :].astype(int)\n",
    "y_labeled = pd.DataFrame(y_labeled)\n",
    "\n",
    "# UNLABELED DATA\n",
    "X_questions_unlabeled = X_questions.drop(index=X_questions_labeled.index)\n",
    "X_drugs_unlabeled = X_drugs.drop(index=X_drugs_labeled.index)\n",
    "X_unlabeled = np.concatenate((X_questions_unlabeled, X_drugs_unlabeled), axis=1) # A junção das duas tabelas\n",
    "y_unlabeled = y.drop(index=y_labeled.index)\n",
    "\n",
    "X_questions_unlabeled = pd.DataFrame(X_questions_unlabeled)\n",
    "X_drugs_unlabeled = pd.DataFrame(X_drugs_unlabeled)\n",
    "X_unlabeled = pd.DataFrame(X_unlabeled)\n",
    "y_unlabeled = pd.DataFrame(y_unlabeled)\n",
    "\n",
    "random_state = 42 # set a random state for reproducibility\n",
    "indices = X_questions_labeled.index.tolist() # get the indices of the dataframes\n",
    "shuffled_indices = pd.DataFrame(indices).sample(frac=1, random_state=random_state).values.ravel() # shuffle the indices\n",
    "X_questions_labeled = X_questions_labeled.loc[shuffled_indices, :] # sort X_questions_labeled by the shuffled indices\n",
    "y_labeled = y_labeled.loc[shuffled_indices, :] # sort y_labeled by the shuffled indices\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth=6,  gamma=0.7, eta=0.01, min_child_weight=1, subsample=0.8, \n",
    "                            colsample_bytree=0.8, scale_pos_weight=1)\n",
    "\n",
    "n_clusters = 2\n",
    "model = AgglomerativeClustering(n_clusters=n_clusters, distance_threshold=None)\n",
    "model.fit(X_unlabeled)\n",
    "\n",
    "Z = linkage(X_unlabeled, method='ward')\n",
    "plt.figure(figsize=(10, 5)) # plot the dendrogram\n",
    "dendrogram(Z, truncate_mode='lastp', p=n_clusters)\n",
    "plt.show()\n",
    "\n",
    "labels = model.labels_\n",
    "unique_labels = np.unique(labels)\n",
    "clusters = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(X_unlabeled.iloc[i:i+1, :])\n",
    "    # clusters[label] = clusters[label].append(X_unlabeled.iloc[i:i+1, :])\n",
    "    \n",
    "for key in clusters.keys():\n",
    "    clusters[key] = pd.concat(clusters[key])\n",
    "\n",
    "clf = trainClassifier(X_labeled, y_labeled, clusters, clf, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
